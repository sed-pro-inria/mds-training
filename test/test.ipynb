{
 "metadata": {
  "name": "",
  "signature": "sha256:a057b47614cf5d10d9aaa4279015734cfd086d96fe3041afbc3b765db6cf57f4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Software testing\n",
      "================"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What is a test?\n",
      "---------------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A test is the specification of an usage of your project, your program or a subset of the\n",
      "functions of your program, together with the expected result."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "cat >hello.c <<EOF\n",
      "#include <stdlib.h>\n",
      "#include <stdio.h>\n",
      "\n",
      "int main() {\n",
      "  printf(\"Hello world!\");\n",
      "  return EXIT_SUCCESS;\n",
      "}\n",
      "EOF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "gcc -o hello hello.c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Specification : when `./hello` is run,\n",
      "- the message \u201c`Hello world!`\u201d is printed,\n",
      "- the program returns with a success as status code."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ideally, this specification should be automatizable: a test is then a program that checks\n",
      "that the program or the function behaves consistently with the specification.  Such a program is generally a sequence of function calls and assertion checks to verify the behavior of these calls.\n",
      "Automatic testing allows the program to be tested on a regular basis, for example every time the program is compiled, such that the developer is warned for regressions as early as possible."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "cat >hello_test.sh <<EOF\n",
      "#!bash\n",
      "\n",
      "# - the message \u201c`Hello world!`\u201d is printed\n",
      "if ! ./hello >/dev/null; then\n",
      "   echo TEST FAILS\n",
      "   exit 1\n",
      "fi\n",
      "\n",
      "# - the program returns with a success as status code\n",
      "if [ `./hello` != \"Hello world!\" ]; then\n",
      "   echo TEST FAILS\n",
      "   exit 1\n",
      "fi\n",
      "\n",
      "echo SUCCESS\n",
      "EOF\n",
      "chmod +x hello_test.sh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "./hello_test.sh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Testing C programs and functions\n",
      "--------------------------------\n",
      "\n",
      "We use the CUnit framework for writting tests. Using testing framework provides facilities for logging test reports in a conventional form such that other tools like the continuous integration plateform can survey test progresses.\n",
      "Let us illustrate the use of CUnit with a simple function that always returns 0."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "cat >zero.h <<EOF\n",
      "int zero(void);\n",
      "EOF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "cat >zero.c <<EOF\n",
      "#include \"zero.h\"\n",
      "\n",
      "int zero(void)\n",
      "{\n",
      "    return 0;\n",
      "}\n",
      "EOF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The test will check that `zero()` obeys to its specification, i.e. that the function returns 0. This check is done with the assertion `CU_ASSERT_EQUAL(zero(), 0);`.\n",
      "In CUnit, tests are organized in test suites. Each test suite is performed in a certain execution environment whose initialization and finalization can be customized: here `init_suite()` and `clean_suite()` are kept empty for the sole suite that we declare with `CU_add_suite()`.  The test function `test_zero` is installed in this suite with `CU_add_test()`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "cat >test_zero.c <<EOF\n",
      "#include <CUnit/Basic.h>\n",
      "#include <stdlib.h>\n",
      "#include \"zero.h\"\n",
      "\n",
      "int init_suite()\n",
      "{\n",
      "    return 0;\n",
      "}\n",
      "\n",
      "int clean_suite()\n",
      "{\n",
      "    return 0;\n",
      "}\n",
      "\n",
      "void test_zero()\n",
      "{\n",
      "    CU_ASSERT_EQUAL(zero(), 0);\n",
      "}\n",
      "\n",
      "void add_tests() {\n",
      "    CU_pSuite suite = CU_add_suite(\"suite\", init_suite, clean_suite);\n",
      "    CU_add_test(suite, \"test_zero\", test_zero);\n",
      "}\n",
      "\n",
      "int run_tests() {\n",
      "    unsigned int number_of_tests_failed;\n",
      "    CU_basic_set_mode(CU_BRM_VERBOSE);\n",
      "    CU_basic_run_tests();\n",
      "    number_of_tests_failed = CU_get_number_of_tests_failed();\n",
      "    CU_cleanup_registry();\n",
      "    return number_of_tests_failed;\n",
      "}\n",
      "\n",
      "int main()\n",
      "{\n",
      "    CU_initialize_registry();\n",
      "    add_tests();\n",
      "    if (run_tests() == 0) {\n",
      "         return EXIT_SUCCESS;\n",
      "    }\n",
      "    else {\n",
      "         return EXIT_FAILURE;\n",
      "    }\n",
      "}\n",
      "EOF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- `CU_ASSERT_TRUE(e)` checks that `e` evaluates to true,\n",
      "- `CU_ASSERT(e)` is equivalent to `CU_ASSERT_TRUE(e)`,\n",
      "- `CU_ASSERT_FALSE(e)` checks that `e` evaluates to false: it is equivalent to `CU_ASSERT_TRUE(!e)`,\n",
      "- `CU_ASSERT_EQUAL(a, b)` is equivalent to `CU_ASSERT_TRUE(a == b)`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "cat >CMakeLists.txt <<EOF\n",
      "cmake_minimum_required(VERSION 2.8)\n",
      "cmake_policy(VERSION 2.8)\n",
      "project(zero)\n",
      "enable_testing()\n",
      "add_executable(test_zero test_zero.c zero.c)\n",
      "target_link_libraries(test_zero cunit)\n",
      "add_test(test_zero test_zero)\n",
      "EOF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "mkdir -p build/\n",
      "cd build/\n",
      "cmake ..\n",
      "make"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "cd build\n",
      "ctest"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test project /home/tmartine/sed/mds-training/test/build\n",
        "    Start 1: test_counter\n",
        "1/1 Test #1: test_counter .....................   Passed    0.00 sec\n",
        "\n",
        "100% tests passed, 0 tests failed out of 1\n",
        "\n",
        "Total Test time (real) =   0.00 sec\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unit tests\n",
      "----------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A unit test is a test that only checks a single function.\n",
      "Writing unit tests for every functions help to isolate which function is broken in case of regression."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Functional tests\n",
      "----------------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A functional test is a test that checks a certain sequence of function calls that corresponds to a functionality of the project: typically, this is a sequence that can occur during the typical life cycle of the program."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "cat >counter.h <<EOF\n",
      "void reset_counter(void);\n",
      "\n",
      "void increment_counter(void);\n",
      "\n",
      "int get_counter_value(void);\n",
      "EOF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "cat >counter.c <<EOF\n",
      "#include \"counter.h\"\n",
      "\n",
      "int counter;\n",
      "\n",
      "void reset_counter(void) {\n",
      "    counter = 0;\n",
      "}\n",
      "\n",
      "void increment_counter(void) {\n",
      "    counter++;\n",
      "}\n",
      "\n",
      "int get_counter_value(void) {\n",
      "    return counter;\n",
      "}\n",
      "\n",
      "EOF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "cat >test_counter.c <<EOF\n",
      "#include <CUnit/Basic.h>\n",
      "#include <stdlib.h>\n",
      "#include \"counter.h\"\n",
      "\n",
      "int init_suite()\n",
      "{\n",
      "    return 0;\n",
      "}\n",
      "\n",
      "int clean_suite()\n",
      "{\n",
      "    return 0;\n",
      "}\n",
      "\n",
      "void test_counter()\n",
      "{\n",
      "    reset_counter();\n",
      "    increment_counter();\n",
      "    increment_counter();\n",
      "    increment_counter();\n",
      "    CU_ASSERT_EQUAL(get_counter_value(), 3);\n",
      "}\n",
      "\n",
      "void add_tests() {\n",
      "    CU_pSuite suite = CU_add_suite(\"suite\", init_suite, clean_suite);\n",
      "    CU_add_test(suite, \"test_counter\", test_counter);\n",
      "}\n",
      "\n",
      "int run_tests() {\n",
      "    unsigned int number_of_tests_failed;\n",
      "    CU_basic_set_mode(CU_BRM_VERBOSE);\n",
      "    CU_basic_run_tests();\n",
      "    number_of_tests_failed = CU_get_number_of_tests_failed();\n",
      "    CU_cleanup_registry();\n",
      "    return number_of_tests_failed;\n",
      "}\n",
      "\n",
      "int main()\n",
      "{\n",
      "    CU_initialize_registry();\n",
      "    add_tests();\n",
      "    if (run_tests() == 0) {\n",
      "         return EXIT_SUCCESS;\n",
      "    }\n",
      "    else {\n",
      "         return EXIT_FAILURE;\n",
      "    }\n",
      "}\n",
      "EOF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "cat >CMakeLists.txt <<EOF\n",
      "cmake_minimum_required(VERSION 2.8)\n",
      "cmake_policy(VERSION 2.8)\n",
      "project(counter)\n",
      "enable_testing()\n",
      "add_executable(test_counter test_counter.c counter.c)\n",
      "target_link_libraries(test_counter cunit)\n",
      "add_test(test_counter test_counter)\n",
      "EOF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "mkdir -p build\n",
      "cd build\n",
      "cmake ..\n",
      "make"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-- Configuring done\n",
        "-- Generating done\n",
        "-- Build files have been written to: /home/tmartine/sed/mds-training/test/build\n",
        "[100%] Built target test_counter\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "cd build\n",
      "ctest"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "     CUnit - A Unit testing framework for C - Version 2.1-0\n",
        "     http://cunit.sourceforge.net/\n",
        "\n",
        "\n",
        "Suite: suite\n",
        "  Test: test_counter ... passed\n",
        "\n",
        "--Run Summary: Type      Total     Ran  Passed  Failed\n",
        "               suites        1       1     n/a       0\n",
        "               tests         1       1       1       0\n",
        "               asserts       1       1       1       0\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Code Coverage\n",
      "-------------\n",
      "\n",
      "Code coverage is the set of execution paths (i.e., set of occurrences of instructions in the code) that are covered by the tests.  Ideally, this set should be equal to the whole program to ensure that the whole program is tested."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Macros\n",
      "------\n",
      "\n",
      "`CU_add_test()` and `CU_add_suite()` are functions that may fail if the CUnit environment is not properly initialized.  It is a good practice to check that their result indicates a success, and to signal the error otherwise.  We define a couple of macros to handle that."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#define ADD_TEST_TO_SUITE(suite, test) \\\n",
      "if ((CU_add_test(suite, #test, test) == NULL)) { \\\n",
      "    CU_cleanup_registry(); \\\n",
      "    return CU_get_error(); \\\n",
      "}\n",
      "\n",
      "#define ADD_SUITE_TO_REGISTRY(suite) \\\n",
      "suite = CU_add_suite(#suite, init_suite, clean_suite); \\\n",
      "if (suite == NULL) { \\\n",
      "  CU_cleanup_registry(); \\\n",
      "  return CU_get_error(); \\\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ADD_SUITE_TO_REGISTRY(suite);\n",
      "ADD_TEST_TO_SUITE(suite, test_counter);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Test-Driven Development\n",
      "-----------------------\n",
      "\n",
      "The Test-Driven Development methodology relies on these three principles:\n",
      "- test first, implement after (and every test should initially fail),\n",
      "- every functionality should be tested,\n",
      "- the development flows over short iterations of the cycle: test, code, refactor."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}